{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4577a5d4",
   "metadata": {},
   "source": [
    "# Project 1 - Building & Evaluating ML Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c48d26f",
   "metadata": {},
   "source": [
    "In this project, you will explore a dataset containing **music-related attributes** and build machine learning models for classification and regression tasks. This project requires you to:\n",
    "\n",
    "1. Carry exploratory data analysis to gather knowledge from data\n",
    "2. Apply data visualization techniques\n",
    "3. Build transformation pipelines for data preprocessing and data cleaning\n",
    "4. Select machine learning algorithms for regression and classification tasks\n",
    "5. Design pipelines for hyperparameter tuning and model selection\n",
    "6. Implement performance evaluation metrics and evaluate results\n",
    "7. Report observations, propose business-centric solutions and propose mitigating strategies\n",
    "\n",
    "You will select your **own classification and regression tasks** based on the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34003b7c-b55c-48bc-85aa-05b2fe8ee837",
   "metadata": {},
   "source": [
    "## Deliverables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb484cc",
   "metadata": {},
   "source": [
    "As part of this project, you should deliver the following materials:\n",
    "\n",
    "1. [**4-page IEEE-format paper**](https://www.ieee.org/conferences/publishing/templates.html). Write a paper with no more than 4 pages addressing the **``tasks``** posed below. When writing this report, consider a business-oriented person as your reader (e.g. your PhD advisor, your internship manager, etc.). Tell *the story* for each datasets' goal and propose solutions by addressing (at least) the **``tasks posed below``**.\n",
    "\n",
    "2. **Python Code**. Create two separate Notebooks: (1) \"training.ipynb\" used for training and hyperparameter tuning, (2) \"test.ipynb\" for evaluating the final trained model in the test set. The \"test.ipynb\" should load all trained objects and simply evaluate the performance. So don't forget to **push the trained models** to your repository to allow us to run it.\n",
    "\n",
    "All of your code should run without any errors and be well-documented. \n",
    "\n",
    "3. **README.md file**. Edit the readme.md file in your repository and how to use your code. If there are user-defined parameters, your readme.md file must clearly indicate so and demonstrate how to use your code.\n",
    "\n",
    "This is an **individual assignment**. \n",
    "\n",
    "These deliverables are **due Monday, March 3 @ 11:59pm**. Late submissions will not be accepted, so please plan accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04efb838",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6af17a9",
   "metadata": {},
   "source": [
    "# About the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dc2f64",
   "metadata": {},
   "source": [
    "This dataset contains attributes of songs played on Spotify until 2022, including their duration and various musical characteristics. It provides an opportunity to analyze how different song features relate to playtime and genre classification. The  dataset is available in the ```Spotify_Song_Attributes.csv``` file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233e42b2-61bb-4f5c-bdad-955e52a265f7",
   "metadata": {},
   "source": [
    "### Attribute Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7c3457-31d9-4e31-9cf3-98a23d129008",
   "metadata": {},
   "source": [
    "\n",
    "1. **trackName** - The name of the track.  \n",
    "2. **artistName** - The name of the artist or band associated with the track.  \n",
    "3. **msPlayed** - The duration in milliseconds that the track was played.  \n",
    "4. **genre** - The genre or genres associated with the track.  \n",
    "5. **danceability** - A measure of how suitable a track is for dancing.  \n",
    "6. **energy** - The energy level of the track.  \n",
    "7. **key** - The key of the track (e.g., C, D, E).  \n",
    "8. **loudness** - The overall loudness of the track in decibels (dB).  \n",
    "9. **mode** - The modality of the track (1 = major, 0 = minor).  \n",
    "10. **speechiness** - The presence of spoken words in the track.  \n",
    "11. **acousticness** - The acousticness of the track.  \n",
    "12. **instrumentalness** - The probability of the track being instrumental.  \n",
    "13. **liveness** - A measure of the presence of a live audience in the track.  \n",
    "14. **valence** - The musical positiveness or happiness conveyed by the track.  \n",
    "15. **tempo** - The tempo of the track in beats per minute (BPM).  \n",
    "16. **type** - The type of the Spotify track.  \n",
    "17. **id** - The unique identifier of the track.  \n",
    "18. **uri** - The Spotify URI for the track.  \n",
    "19. **track_href** - A link to the Spotify Web API endpoint for the track.  \n",
    "20. **analysis_url** - A link to the audio analysis of the track.  \n",
    "21. **duration_ms** - The duration of the track in milliseconds.  \n",
    "22. **time_signature** - The time signature of the track.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bf5178",
   "metadata": {},
   "source": [
    "# Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98f67ff",
   "metadata": {},
   "source": [
    "## **Step 1: Exploratory Data Analysis (EDA)**  \n",
    "\n",
    "### **What to Do**  \n",
    "- Load the dataset and inspect its structure using `.head()`, `.info()`, `.describe()`.  \n",
    "- Check for missing values and determine how to handle them (drop, impute, etc.).  \n",
    "- Identify duplicates and remove them if necessary.  \n",
    "- Analyze basic statistics of numerical features:  \n",
    "  - Mean, median, standard deviation, min, max.  \n",
    "  - Correlations between variables.  \n",
    "- Check the distribution of key features using:  \n",
    "  - Histograms  \n",
    "  - Box plots   \n",
    "  - others\n",
    "- Analyze relationships between features using:  \n",
    "  - Correlation heatmaps  \n",
    "  - Scatter plots for key relationships  \n",
    "  - If applicable, analyze categorical features (e.g., genre) using bar charts.\n",
    "  - others\n",
    "- Check for potential outliers and determine how to handle them.  \n",
    "\n",
    "**``Task 1. Provide a summary of findings from EDA (bullet points or short analysis).``**\n",
    "\n",
    "**``Task 2. Provide at least three visualizations showing trends or insights from the dataset.``**  \n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9365353b",
   "metadata": {},
   "source": [
    "## **Step 2: Data Preprocessing & Cleaning Pipelines**  \n",
    "\n",
    "### **What to Do**  \n",
    "- Handle missing values (e.g., drop rows, impute with mean/median).  \n",
    "- Normalize or standardize numerical features if necessary.  \n",
    "- Encode categorical variables (if applicable).  \n",
    "- Remove outliers if they affect model performance.  \n",
    "- Split the dataset into training (80%) and testing (20%) sets.  \n",
    "- Store preprocessing steps in a pipeline for reuse.  \n",
    "\n",
    "**``Task 3. Provide a written summary of the preprocessing steps.``**  \n",
    "\n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da4e450",
   "metadata": {},
   "source": [
    "## **Step 3: Select a Classification and Regression Task**  \n",
    "\n",
    " \n",
    "- Pick **one classification problem** (e.g., predict high/low `danceability`, predict a song’s `energy` category, etc.).  \n",
    "- Pick **one regression problem** (e.g., predict a song’s `tempo` based on features, predict `loudness` based on other audio properties, etc.).  \n",
    "\n",
    "**``Task 4. Clearly state the target variable for both classification and regression AND Explain why this task is interesting.``**  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859771c5",
   "metadata": {},
   "source": [
    "## **Step 4: Training Machine Learning Models**  \n",
    "\n",
    "### **Classification Task**  \n",
    "- Train and compare:  \n",
    "    - Logistic Regression  \n",
    "    - Random Forest Classifier  \n",
    "\n",
    "- Tune hyperparameters using `GridSearchCV` or `RandomizedSearchCV`.  \n",
    "\n",
    "- Measure performance using:  \n",
    "    - Accuracy  \n",
    "    - Precision, Recall, F1-score  \n",
    "    - Confusion matrix  \n",
    "    - ROC-AUC curve  \n",
    "\n",
    "- Save trained models using joblib\n",
    "- Save the preprocessing pipeline (scalers, encoders, etc.)\n",
    "\n",
    "\n",
    "### **Regression Task**  \n",
    "- Train and compare:  \n",
    "    - Linear Regression (with and without regularization, e.g., Ridge/Lasso)  \n",
    "    - Decision Tree Regressor  \n",
    "\n",
    "- Tune hyperparameters to optimize model performance using `GridSearchCV` or `RandomizedSearchCV`.    \n",
    "\n",
    "- Compare models using:  \n",
    "    - R² (Coefficient of Determination)  \n",
    "    - Mean Absolute Error (MAE)  \n",
    "    - Mean Squared Error (MSE)  \n",
    "    - Root Mean Squared Error (RMSE)\n",
    "\n",
    "- Save trained models using joblib\n",
    "- Save the preprocessing pipeline (scalers, encoders, etc.)\n",
    "\n",
    "\n",
    "**``Task 5. After completing all steps above, provide the following:``** \n",
    "- Training performance metrics for each model.  \n",
    "- A short explanation of which model performed better and why.\n",
    "- Are there any differences when adding regularization into regression? Which features are more important? \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d656f317",
   "metadata": {},
   "source": [
    "## **Step 5: Performance Evaluation**  \n",
    "\n",
    "- Load Test Data\n",
    "\n",
    "    - Load the original dataset\n",
    "    - Apply the same preprocessing pipeline used in training.ipynb\n",
    "    - Extract the 20% test set (the same as used during training)\n",
    "    - Load Trained Models & Pipeline\n",
    "\n",
    "- Load the saved classification model\n",
    "- Load the saved regression model\n",
    "- Load the preprocessing pipeline\n",
    "\n",
    "**Evaluate Classification Model**\n",
    "\n",
    "- Generate predictions on the test set. Compute:\n",
    "    - Accuracy\n",
    "    - Precision, Recall, F1-score\n",
    "    - Confusion Matrix\n",
    "    - ROC-AUC Curve\n",
    "\n",
    "**Evaluate Regression Model**\n",
    "\n",
    "- Generate predictions on the test set. Compute:\n",
    "    - R² (Coefficient of Determination)\n",
    "    - MAE (Mean Absolute Error)\n",
    "    - MSE (Mean Squared Error)\n",
    "    - RMSE (Root Mean Squared Error)\n",
    "\n",
    "**``Task 6. After completing all steps above, provide the following:``**\n",
    "\n",
    "- Compare models and justify which one is better for each task.\n",
    "- At least one visualizations per classification tasks (e.g., confusion matrix, ROC curve, precision-recall curves).  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de61cf3",
   "metadata": {},
   "source": [
    "## **Step 6: Report Findings & Business Insights**  \n",
    "\n",
    "**``Task 7. Interpret the results.``**\n",
    "- What trends did you observe?  \n",
    "- How well do these models generalize?  \n",
    " - How can this analysis be useful to music streaming platforms?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24bc40d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66027c2c",
   "metadata": {},
   "source": [
    "# Submit Your Solution\n",
    "\n",
    "Confirm that you've successfully completed the assignment.\n",
    "\n",
    "Along with the Notebook, include a PDF of the notebook with your solutions.\n",
    "\n",
    "```add``` and ```commit``` the final version of your work, and ```push``` your code to your GitHub repository.\n",
    "\n",
    "Submit the URL of your GitHub Repository as your assignment submission on Canvas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa2d31e",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
